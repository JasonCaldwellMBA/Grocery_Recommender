{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modeling Recommendation Engine v2 <sup>[1]</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logsumexp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 80/20 split earlier\n",
    "df_train = pd.read_csv('../Data/training_data.csv')\n",
    "df_test = pd.read_csv('../Data/testing_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Also need full dataset to index users for easier comparisons later.\n",
    "# Make sure to avoid data leakage and not mix up the analysis on different DataFrames\n",
    "df = pd.read_csv('../Data/eda_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subset of data didn't make a difference\n",
    "# df_train_subset = df_train.iloc[np.random.choice(df_train.index, size=10000, replace=False)]\n",
    "# print(df_train_subset.shape)\n",
    "# print(df_train.reviewerID.nunique())\n",
    "# print(df_train.asin.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a user index\n",
    "To retrieve information given a specific user_id in a more convenient way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The key features and ids from earlier analysis.\n",
    "# Note that additional features could be included if desired; except for the target feature: 'overall'.\n",
    "user_info = df[['title', 'also_buy', 'rank', 'asin', 'reviewerID', 'reviewText', 'summary']]\n",
    "user_info.set_index('reviewerID', inplace=True)\n",
    "user_info.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_ids_larger_1 = pd.value_counts(df.reviewerID, sort=False) > 1\n",
    "user_ids_larger_1 = user_ids_larger_1[user_ids_larger_1].index\n",
    "len(user_ids_larger_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.loc[user_ids_larger_1]\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation functions\n",
    "\n",
    "Used to test your `estimate` method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(estimate_f):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    \n",
    "    ids_to_estimate = zip(df_test.reviewerID, df_test.asin)\n",
    "    estimated = np.array([estimate_f(u,i) for (u,i) in ids_to_estimate])\n",
    "    real = df_test.overall.values\n",
    "    return compute_rmse(estimated, real)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Several Custom Similarity Functions\n",
    "\n",
    "### Euclidean 'similarity'\n",
    "\n",
    "$$ sim(x,y) = \\frac{1}{1 + \\sqrt{\\sum (x - y)^2}}$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def euclidean(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return their euclidean 'similarity'.\"\"\"\n",
    "    diff = s1 - s2\n",
    "    return 1 / (1 + np.sqrt(np.sum(diff ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cosine similarity\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x . y)}{\\sqrt{(x . x) (y . y)}} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cosine(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return their cosine similarity.\"\"\"\n",
    "    return np.sum(s1 * s2) / np.sqrt(np.sum(s1 ** 2) * np.sum(s2 ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Pearson correlation\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x - \\bar x).(y - \\bar y)}{\\sqrt{(x - \\bar x).(x - \\bar x) * (y - \\bar y)(y - \\bar y)}} $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pearson(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return a pearson correlation.\"\"\"\n",
    "    s1_c = s1 - s1.mean()\n",
    "    s2_c = s2 - s2.mean()\n",
    "    return np.sum(s1_c * s2_c) / np.sqrt(np.sum(logsumexp(s1_c ** 2)) * np.sum(logsumexp(s2_c ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Jaccard similarity\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x . y)}{(x . x) + (y . y) - (x . y)} $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    dotp = np.sum(s1 * s2)\n",
    "    return dotp / (np.sum(s1 ** 2) + np.sum(s2 ** 2) - dotp)\n",
    "\n",
    "def binjaccard(s1, s2):\n",
    "    dotp = s1.index.intersection(s2.index).size\n",
    "    return dotp / (s1.sum() + s2.sum() - dotp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CollaborativeSimilarityRecommendation:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self, similarity=None):\n",
    "        \"\"\" Prepare datastructures for estimation. \"\"\"\n",
    "        \n",
    "        try:\n",
    "            self.all_user_profiles = df_train.pivot_table('overall', index='asin', columns='reviewerID')\n",
    "        except IndexError as e:\n",
    "            logging.exception(e)\n",
    "            \n",
    "        self._similarity = similarity\n",
    "        \n",
    "    @property\n",
    "    def similarity(self):\n",
    "        return self._similarity\n",
    "    \n",
    "    @similarity.setter\n",
    "    def similarity(self, value):\n",
    "        self._similarity = value\n",
    "        \n",
    "    def estimate(self, user_id, product_id):\n",
    "        \"\"\" Ratings weighted by correlation similarity. \"\"\"\n",
    "        \n",
    "        user_condition = df_train.reviewerID != user_id\n",
    "        movie_condition = df_train.asin == product_id\n",
    "        ratings_by_others = df_train.loc[user_condition & movie_condition]\n",
    "        if ratings_by_others.empty: \n",
    "            return 4.0\n",
    "        \n",
    "        ratings_by_others.set_index('reviewerID', inplace=True)\n",
    "        their_ids = ratings_by_others.index\n",
    "        their_ratings = ratings_by_others.overall\n",
    "        their_profiles = self.all_user_profiles[their_ids]\n",
    "        user_profile = self.all_user_profiles[user_id]\n",
    "        sims = their_profiles.apply(lambda profile: self.similarity(profile, user_profile), axis=0)\n",
    "        ratings_sims = pd.DataFrame({'sim': sims, 'overall': their_ratings})\n",
    "        ratings_sims = ratings_sims[ratings_sims.sim > 0]\n",
    "        if ratings_sims.empty:\n",
    "            return their_ratings.mean()\n",
    "        else:\n",
    "            return np.average(ratings_sims.overall, weights=ratings_sims.sim)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reco = CollaborativeSimilarityRecommendation(pearson)\n",
    "print('RMSE for Pearson: %s' % evaluate(reco.estimate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "1) Unata 2015 [Hands-on with PyData: How to Build a Minimal Recommendation Engine](https://www.youtube.com/watch?v=F6gWjOc1FUs).  "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cef1f773",
   "language": "python",
   "display_name": "PyCharm (pycon2015_tutorial322)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}